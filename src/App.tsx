import React, { useState, useEffect, useRef } from 'react';
import { MetadataPanel } from './components/MetadataPanel';
import { RecordingControls } from './components/RecordingControls';
import { NotesEditor } from './components/NotesEditor';
import { AudioPlayer, AudioPlayerRef } from './components/AudioPlayer';
import { HelpButton } from './components/HelpButton';
import { TranscriptionConfig } from './components/TranscriptionConfig';
import { TranscriptionPanel } from './components/TranscriptionPanel';
import { FileManagerService } from './services/fileManager';
import { saveBackup, loadBackup, clearBackup, hasBackup, getBackupAge } from './services/autoBackup';
import { speechToTextService, SpeechToTextService } from './services/speechToText';
import type { MeetingInfo, SpeechToTextConfig, TranscriptionResult } from './types/types';
import './styles/global.css';

export const App: React.FC = () => {
  const [folderPath, setFolderPath] = useState<string>('');
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [meetingInfo, setMeetingInfo] = useState<MeetingInfo>({
    title: `${new Date().toISOString().split('T')[0]} _ `,
    date: new Date().toISOString().split('T')[0],
    time: new Date().toTimeString().slice(0, 5),
    location: '',
    host: '',
    attendees: ''
  });
  const [notes, setNotes] = useState<string>('');
  const [timestampMap, setTimestampMap] = useState<Map<number, number>>(new Map());
  const [speakersMap, setSpeakersMap] = useState<Map<number, string>>(new Map());
  const [recordingStartTime, setRecordingStartTime] = useState<number>(0);
  const [hasUnsavedChanges, setHasUnsavedChanges] = useState(false);
  const [isSaved, setIsSaved] = useState(false);
  const [savedNotesSnapshot, setSavedNotesSnapshot] = useState<string>('');
  const [isLiveMode, setIsLiveMode] = useState(true); // true = live recording, false = loaded project
  const [showBackupDialog, setShowBackupDialog] = useState(false);
  const [backupAge, setBackupAge] = useState<number | null>(null);
  const autoSaveTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const audioPlayerRef = useRef<AudioPlayerRef>(null);
  
  // Speech-to-Text states
  const [showTranscriptionConfig, setShowTranscriptionConfig] = useState(false);
  const [transcriptionConfig, setTranscriptionConfig] = useState<SpeechToTextConfig | null>(null);
  const [transcriptions, setTranscriptions] = useState<TranscriptionResult[]>([]);
  const [isOnline, setIsOnline] = useState(navigator.onLine);

  // Check browser compatibility
  useEffect(() => {
    if (!FileManagerService.isSupported()) {
      console.warn(
        'File System Access API not supported. Files will be downloaded instead.'
      );
    }
  }, []);
  
  // Load Speech-to-Text config on mount
  useEffect(() => {
    const savedConfig = SpeechToTextService.loadConfig();
    if (savedConfig) {
      setTranscriptionConfig(savedConfig);
      speechToTextService.initialize(savedConfig);
      console.log('üé§ Speech-to-Text config loaded');
    }
  }, []);
  
  // Monitor online/offline status
  useEffect(() => {
    const handleOnline = () => setIsOnline(true);
    const handleOffline = () => setIsOnline(false);
    
    window.addEventListener('online', handleOnline);
    window.addEventListener('offline', handleOffline);
    
    return () => {
      window.removeEventListener('online', handleOnline);
      window.removeEventListener('offline', handleOffline);
    };
  }, []);
  
  // Check for existing backup on mount
  useEffect(() => {
    const checkBackup = async () => {
      if (hasBackup()) {
        const age = getBackupAge();
        setBackupAge(age);
        setShowBackupDialog(true);
      }
    };
    checkBackup();
  }, []);

  // Track unsaved changes
  useEffect(() => {
    // C√≥ d·ªØ li·ªáu ch∆∞a l∆∞u n·∫øu:
    // 1. ƒêang recording
    // 2. C√≥ audio/notes nh∆∞ng ch∆∞a save l·∫ßn ƒë·∫ßu
    // 3. ƒê√£ save nh∆∞ng notes b·ªã s·ª≠a ƒë·ªïi
    const notesModified = isSaved && savedNotesSnapshot !== notes;
    const hasData = isRecording || (!isSaved && (audioBlob !== null || notes.trim().length > 0)) || notesModified;
    setHasUnsavedChanges(hasData);
  }, [isRecording, audioBlob, notes, isSaved, savedNotesSnapshot]);
  
  // Auto-save to localStorage with debounce (every 3 seconds after changes)
  useEffect(() => {
    // Auto-save whenever there are unsaved changes (including after first save)
    // Backup will be cleared only when user explicitly saves
    if (hasUnsavedChanges) {
      if (autoSaveTimeoutRef.current) {
        clearTimeout(autoSaveTimeoutRef.current);
      }
      
      autoSaveTimeoutRef.current = setTimeout(() => {
        const meetingInfoForBackup = {
          projectName: meetingInfo.title,
          location: meetingInfo.location,
          participants: meetingInfo.attendees
        };
        
        saveBackup(
          meetingInfoForBackup,
          notes,
          timestampMap,
          recordingStartTime,
          audioBlob,
          isSaved
        );
      }, 3000); // Auto-save 3 seconds after last change
    }
    
    return () => {
      if (autoSaveTimeoutRef.current) {
        clearTimeout(autoSaveTimeoutRef.current);
      }
    };
  }, [meetingInfo, notes, timestampMap, recordingStartTime, audioBlob, hasUnsavedChanges, isSaved]);

  // Switch to live mode when starting a new recording
  useEffect(() => {
    if (isRecording) {
      setIsLiveMode(true);
    }
  }, [isRecording]);

  // Debug: Log when meetingInfo changes
  useEffect(() => {
    console.log('üìù App meetingInfo state updated:', meetingInfo);
  }, [meetingInfo]);

  // Prevent accidental page close/reload when recording or has unsaved data
  useEffect(() => {
    const handleBeforeUnload = (e: BeforeUnloadEvent) => {
      if (hasUnsavedChanges) {
        // Chu·∫©n modern browsers
        e.preventDefault();
        // Chrome requires returnValue to be set
        e.returnValue = 'B·∫°n c√≥ d·ªØ li·ªáu ch∆∞a l∆∞u. B·∫°n c√≥ ch·∫Øc mu·ªën r·ªùi kh·ªèi trang?';
        return e.returnValue;
      }
    };

    window.addEventListener('beforeunload', handleBeforeUnload);
    return () => window.removeEventListener('beforeunload', handleBeforeUnload);
  }, [hasUnsavedChanges]);

  // Clear unsaved changes flag after successful save
  const handleAudioBlobChange = (blob: Blob | null) => {
    setAudioBlob(blob);
  };

  const handleSaveComplete = () => {
    setIsSaved(true);
    setHasUnsavedChanges(false);
    setSavedNotesSnapshot(notes); // Save snapshot to detect future changes
    // Clear auto-backup after successful save
    clearBackup();
  };
  
  const handleRestoreBackup = async () => {
    const backup = await loadBackup();
    if (backup) {
      setMeetingInfo({
        title: backup.meetingInfo.projectName,
        date: new Date().toISOString().split('T')[0],
        time: new Date().toTimeString().slice(0, 5),
        location: backup.meetingInfo.location,
        host: '',
        attendees: backup.meetingInfo.participants
      });
      setNotes(backup.notes);
      setTimestampMap(backup.timestampMap);
      setRecordingStartTime(backup.recordingStartTime);
      if (backup.audioBlob) {
        setAudioBlob(backup.audioBlob);
      }
      setIsSaved(backup.isSaved);
      setShowBackupDialog(false);
      console.log('‚úÖ Backup restored successfully');
    }
  };
  
  const handleDiscardBackup = async () => {
    await clearBackup();
    setShowBackupDialog(false);
    console.log('üóëÔ∏è Backup discarded');
  };

  const handleLoadProject = (loadedData: {
    meetingInfo: MeetingInfo;
    notes: string;
    timestampMap: Map<number, number>;
    speakersMap: Map<number, string>;
    audioBlob: Blob | null;
    recordingStartTime: number;
  }) => {
    console.log('üìÇ App.handleLoadProject - Data received:', {
      meetingInfo: loadedData.meetingInfo,
      notesLength: loadedData.notes.length,
      timestampMapSize: loadedData.timestampMap.size,
      speakersMapSize: loadedData.speakersMap.size,
      audioBlobSize: loadedData.audioBlob?.size || 0,
      hasAudio: loadedData.audioBlob !== null
    });
    
    setMeetingInfo(loadedData.meetingInfo);
    setNotes(loadedData.notes);
    setTimestampMap(loadedData.timestampMap);
    setSpeakersMap(loadedData.speakersMap);
    setAudioBlob(loadedData.audioBlob);
    setRecordingStartTime(loadedData.recordingStartTime);
    setIsSaved(true);
    setHasUnsavedChanges(false);
    setSavedNotesSnapshot(loadedData.notes);
    setIsLiveMode(false); // Switch to timestamp mode when loading project
  };

  // Handle transcription config save
  const handleSaveTranscriptionConfig = (config: SpeechToTextConfig) => {
    setTranscriptionConfig(config);
    speechToTextService.initialize(config);
    console.log('‚úÖ Transcription config updated');
  };

  // Handle new transcription result
  const handleNewTranscription = (result: TranscriptionResult) => {
    setTranscriptions(prev => {
      // N·∫øu l√† k·∫øt qu·∫£ final
      if (result.isFinal) {
        // Lo·∫°i b·ªè k·∫øt qu·∫£ t·∫°m th·ªùi (n·∫øu c√≥)
        const finalResults = prev.filter(item => item.isFinal);
        
        // Ki·ªÉm tra xem k·∫øt qu·∫£ m·ªõi c√≥ ph·∫£i l√† phi√™n b·∫£n m·ªü r·ªông c·ªßa k·∫øt qu·∫£ c≈© kh√¥ng
        // N·∫øu k·∫øt qu·∫£ cu·ªëi c√πng ch·ª©a h·∫ßu h·∫øt text c·ªßa k·∫øt qu·∫£ m·ªõi ho·∫∑c ng∆∞·ª£c l·∫°i
        if (finalResults.length > 0) {
          const lastResult = finalResults[finalResults.length - 1];
          const newText = result.text.trim().toLowerCase();
          const lastText = lastResult.text.trim().toLowerCase();
          
          // Case 1: K·∫øt qu·∫£ m·ªõi l√† phi√™n b·∫£n m·ªü r·ªông c·ªßa k·∫øt qu·∫£ c≈©
          // VD: C≈©: "nh∆∞ v·∫≠y l√†", M·ªõi: "nh∆∞ v·∫≠y l√† c√°i m·∫´u"
          if (newText.startsWith(lastText) && newText.length > lastText.length) {
            console.log('üîÑ Replacing with extended version:', {
              old: lastText.substring(0, 50) + '...',
              new: newText.substring(0, 50) + '...'
            });
            // Thay th·∫ø k·∫øt qu·∫£ c≈© b·∫±ng k·∫øt qu·∫£ m·ªõi
            finalResults[finalResults.length - 1] = result;
            return finalResults;
          }
          
          // Case 2: K·∫øt qu·∫£ c≈© l√† phi√™n b·∫£n m·ªü r·ªông c·ªßa k·∫øt qu·∫£ m·ªõi ‚Üí b·ªè qua k·∫øt qu·∫£ m·ªõi
          // VD: C≈©: "nh∆∞ v·∫≠y l√† c√°i m·∫´u", M·ªõi: "nh∆∞ v·∫≠y l√†"
          if (lastText.startsWith(newText)) {
            console.log('‚è≠Ô∏è Skipping shorter duplicate');
            return prev; // Gi·ªØ nguy√™n
          }
          
          // Case 3: Ki·ªÉm tra ƒë·ªô t∆∞∆°ng ƒë·ªìng cao (>80% gi·ªëng nhau)
          const similarity = calculateSimilarity(newText, lastText);
          if (similarity > 0.8) {
            console.log('‚è≠Ô∏è Skipping similar result (similarity: ' + (similarity * 100).toFixed(0) + '%)');
            return prev;
          }
        }
        
        // Th√™m k·∫øt qu·∫£ m·ªõi
        return [...finalResults, result];
      } else {
        // N·∫øu l√† k·∫øt qu·∫£ t·∫°m th·ªùi, ch·ªâ gi·ªØ 1 k·∫øt qu·∫£ t·∫°m th·ªùi m·ªõi nh·∫•t
        const finalResults = prev.filter(item => item.isFinal);
        return [...finalResults, result];
      }
    });
    
    if (result.isFinal) {
      console.log('‚úÖ Final transcription:', result.text.substring(0, 50) + '...');
    }
  };

  // Calculate text similarity (Levenshtein-based)
  const calculateSimilarity = (text1: string, text2: string): number => {
    const longer = text1.length > text2.length ? text1 : text2;
    const shorter = text1.length > text2.length ? text2 : text1;
    
    if (longer.length === 0) return 1.0;
    
    // Quick check: if one contains the other
    if (longer.includes(shorter)) {
      return shorter.length / longer.length;
    }
    
    // Simple word-based similarity
    const words1 = text1.split(/\s+/);
    const words2 = text2.split(/\s+/);
    const commonWords = words1.filter(w => words2.includes(w)).length;
    
    return (2 * commonWords) / (words1.length + words2.length);
  };

  // Handle seek to audio time
  const handleSeekToAudio = (timeMs: number) => {
    if (audioPlayerRef.current) {
      audioPlayerRef.current.seekTo(timeMs);
      console.log(`‚è≠Ô∏è Seeking to ${(timeMs / 1000).toFixed(2)}s`);
    }
  };

  return (
    <div className="app-container">
      {/* Backup Restoration Dialog */}
      {showBackupDialog && (
        <div style={{
          position: 'fixed',
          top: 0,
          left: 0,
          right: 0,
          bottom: 0,
          backgroundColor: 'rgba(0, 0, 0, 0.7)',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          zIndex: 9999
        }}>
          <div style={{
            backgroundColor: '#1e1e1e',
            border: '2px solid #ffa500',
            borderRadius: '8px',
            padding: '24px',
            maxWidth: '500px',
            boxShadow: '0 4px 16px rgba(0, 0, 0, 0.5)'
          }}>
            <h2 style={{ marginTop: 0, color: '#ffa500' }}>üîÑ Kh√¥i ph·ª•c d·ªØ li·ªáu</h2>
            <p style={{ fontSize: '16px', lineHeight: '1.6' }}>
              Ph√°t hi·ªán d·ªØ li·ªáu t·ª± ƒë·ªông sao l∆∞u t·ª´ <strong>{backupAge !== null ? `${backupAge} ph√∫t` : 'm·ªôt l√∫c'}</strong> tr∆∞·ªõc.
              <br/>
              C√≥ th·ªÉ tr√¨nh duy·ªát ƒë√£ b·ªã ƒë√≥ng ƒë·ªôt ng·ªôt ho·∫∑c b·∫°n ch∆∞a l∆∞u d·ªØ li·ªáu.
            </p>
            <p style={{ fontSize: '14px', color: '#888' }}>
              B·∫°n c√≥ mu·ªën kh√¥i ph·ª•c d·ªØ li·ªáu n√†y kh√¥ng?
            </p>
            <div style={{ display: 'flex', gap: '12px', marginTop: '20px' }}>
              <button
                onClick={handleRestoreBackup}
                style={{
                  flex: 1,
                  padding: '12px 20px',
                  backgroundColor: '#1890ff',
                  color: 'white',
                  border: 'none',
                  borderRadius: '6px',
                  fontSize: '16px',
                  fontWeight: 'bold',
                  cursor: 'pointer'
                }}
              >
                ‚úÖ Kh√¥i ph·ª•c
              </button>
              <button
                onClick={handleDiscardBackup}
                style={{
                  flex: 1,
                  padding: '12px 20px',
                  backgroundColor: '#434343',
                  color: 'white',
                  border: 'none',
                  borderRadius: '6px',
                  fontSize: '16px',
                  cursor: 'pointer'
                }}
              >
                üóëÔ∏è B·ªè qua
              </button>
            </div>
          </div>
        </div>
      )}
      
      <header className="app-header">
        <h1>üìù Live Meeting Notes</h1>
        <div className="status-indicator">
          {navigator.onLine ? 'üåê Online' : 'üì¥ Offline'}
          {hasUnsavedChanges && <span className="unsaved-indicator" title="B·∫°n c√≥ d·ªØ li·ªáu ch∆∞a l∆∞u">‚ö†Ô∏è Ch∆∞a l∆∞u</span>}
          <HelpButton />
        </div>
      </header>

      <MetadataPanel meetingInfo={meetingInfo} onChange={setMeetingInfo} />

      <RecordingControls
        folderPath={folderPath}
        onFolderSelect={setFolderPath}
        isRecording={isRecording}
        onRecordingChange={setIsRecording}
        onAudioBlobChange={handleAudioBlobChange}
        onSaveComplete={handleSaveComplete}
        onLoadProject={handleLoadProject}
        meetingInfo={meetingInfo}
        notes={notes}
        timestampMap={timestampMap}
        speakersMap={speakersMap}
        recordingStartTime={recordingStartTime}
        onRecordingStartTimeChange={setRecordingStartTime}
        audioBlob={audioBlob}
        isSaved={isSaved}
        hasUnsavedChanges={hasUnsavedChanges}
        onShowTranscriptionConfig={() => setShowTranscriptionConfig(true)}
        transcriptionConfig={transcriptionConfig}
        onNewTranscription={handleNewTranscription}
        onClearTranscriptions={() => setTranscriptions([])}
        transcriptions={transcriptions}
      />

      <NotesEditor
        notes={notes}
        onNotesChange={setNotes}
        timestampMap={timestampMap}
        onTimestampMapChange={setTimestampMap}
        recordingStartTime={recordingStartTime}
        isLiveMode={isLiveMode}
        onSpeakersChange={setSpeakersMap}
        initialSpeakers={speakersMap}
      />

      {/* Transcription Panel - Only show when online and configured */}
      {isOnline && transcriptionConfig && (
        <TranscriptionPanel
          transcriptions={transcriptions}
          isTranscribing={isRecording}
          isOnline={isOnline}
          onSeekAudio={handleSeekToAudio}
        />
      )}

      <AudioPlayer ref={audioPlayerRef} audioBlob={audioBlob} />

      {/* Transcription Configuration Modal */}
      <TranscriptionConfig
        visible={showTranscriptionConfig}
        onClose={() => setShowTranscriptionConfig(false)}
        onSave={handleSaveTranscriptionConfig}
        currentConfig={transcriptionConfig}
      />
    </div>
  );
};
